{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial I\n",
        "\n",
        "Implement  basics of prompt engineering using OpenAI Chat Completion APIs. Implement different components of a prompt like user prompt, system prompt, temperature and max tokens. Build prompt templates with variables that can be reused. Use [langchain](https://www.langchain.com/) to create a prompt template and call OpenAI APIs."
      ],
      "metadata": {
        "id": "_CMmWcQsuYDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation\n",
        "\n",
        "Install OpenAI Python library. You can find API reference for OpenAI Python library [here](https://platform.openai.com/docs/introduction)"
      ],
      "metadata": {
        "id": "4EXPNo2Zu7x5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4hzPmUBAuR97"
      },
      "outputs": [],
      "source": [
        "!pip install -qqq openai cohere tiktoken langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import\n",
        "\n",
        "- OpenAI API key  [OpenAI API](https://platform.openai.com/api-keys) keys and get one\n",
        "- Create a new entry in Google Colab Secrets using the above key.\n",
        "- Name the key `openai_api_key`\n",
        "- Get OpenAI API key from Google Secrets\n",
        "<p align=\"center\">\n",
        "<img src=\"https://pbs.twimg.com/media/F93zfjHWQAA1DB1?format=jpg&name=medium\" height=400/>\n",
        "</p>"
      ],
      "metadata": {
        "id": "qtqpZbYUvWOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from rich import print\n",
        "import json"
      ],
      "metadata": {
        "id": "P_8O4Stuu_xa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('openai_api_key')"
      ],
      "metadata": {
        "id": "2rOcfYJRvb2s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import PromptTemplate\n",
        "from langchain.schema import HumanMessage, SystemMessage"
      ],
      "metadata": {
        "id": "b0Q1CgI1Umhe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper function\n",
        "\n",
        "To generate response from OpenAI API\n",
        "\n",
        "Input parameters:\n",
        "- 'prompt': A string representing the user's input or query.\n",
        "- 'system': An optional string representing system-level instructions (default is an empty string).\n",
        "- 'temperature': An optional float parameter controlling the randomness of the response (default is 0.0, making it deterministic).\n",
        "- 'max_tokens': An optional integer specifying the maximum length of the generated response (default is 50 tokens).\n",
        "\n"
      ],
      "metadata": {
        "id": "krPhnUh1wjAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(prompt: str, system: str =\" \", temperature: float =0.0, max_tokens:int = 50):\n",
        "\n",
        "  try:\n",
        "    # Create an OpenAI client using the API key\n",
        "    client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "    # Create an empty list to store messages\n",
        "    messages = []\n",
        "\n",
        "    # If a system-level instruction is provided, add it to the list of messages\n",
        "    if system:\n",
        "      messages.append({\"role\": \"system\", \"content\": system})\n",
        "\n",
        "    # Add the user's input or query as a message\n",
        "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "    # Generate a response using the OpenAI chat completions API, specifying model, messages, temperature, and max_tokens\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-1106\",\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "  except Exception as error:\n",
        "    # Handle any exceptions that may occur during API usage and print the error message\n",
        "    print(error)\n",
        "\n",
        "  # Return the content of the generated response as a string\n",
        "  return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "SghwREjLvz7b"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response_langchain(prompt: str, system: str = \"\", temperature: float = 0.0, max_tokens: int = 50):\n",
        "\n",
        "  # Create a ChatOpenAI instance with specified settings, including the GPT-3.5 Turbo model,\n",
        "  # 'temperature' for controlling randomness, 'max_tokens' for limiting the response length,\n",
        "  # and 'openai_api_key' to authenticate with the OpenAI API.\n",
        "  chat = ChatOpenAI(model_name='gpt-3.5-turbo-1106', temperature=temperature, max_tokens=max_tokens, openai_api_key=openai_api_key)\n",
        "\n",
        "  # Create a list called 'messages' that contains two message objects:\n",
        "  # - A 'SystemMessage' object with content equal to the 'system' parameter.\n",
        "  # - A 'HumanMessage' object with content equal to the 'prompt' parameter.\n",
        "  messages = [SystemMessage(content=system),\n",
        "              HumanMessage(content=prompt),\n",
        "              ]\n",
        "\n",
        "  # Use the 'chat' instance to process the 'messages' list and generate a response.\n",
        "  # Then, return the content of the generated response.\n",
        "  return chat(messages).content"
      ],
      "metadata": {
        "id": "qcNx-ThlUhit"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User prompt"
      ],
      "metadata": {
        "id": "Sv6uyg0P2pAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What is 1+1?\"\n",
        "\n",
        "response = generate_response(prompt)\n",
        "\n",
        "# Uncomment the following line to try out the langchain equivalent, this applies to all the following cells.\n",
        "#response = generate_response_langchain(prompt)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "DTTG3L-u0wPp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8f042a34-61ce-4acc-b3a8-8818a13d55ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m1\u001b[0m+\u001b[1;36m1\u001b[0m equals \u001b[1;36m2\u001b[0m.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> equals <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## System Prompt\n",
        "\n",
        "In the OpenAI API, a system prompt is a textual instruction provided to guide the behavior of the language model during conversation. It is used to set the context or tone of the conversation, providing high-level instructions that influence how the model generates responses to user inputs."
      ],
      "metadata": {
        "id": "MZdiAyMJ2uOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system = \"You are a helpful AI assistant who speaks like a pirate!\"\n",
        "prompt = \"Give me some ideas to spend Thanksgiving weekend\"\n",
        "\n",
        "response = generate_response(prompt,system=system)\n",
        "# response = generate_response_langchain(prompt, system=system)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "mGYi133m09Qq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "2adede5e-55a9-4613-c3c4-d37db9f6737e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Arrr, matey! Here be a few ideas to spend yer Thanksgiving weekend like a true pirate:\n",
              "\n",
              "\u001b[1;36m1\u001b[0m. Host a swashbucklin' feast with yer mateys, complete with a bounty of turkey, grog, and plenty o\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Arrr, matey! Here be a few ideas to spend yer Thanksgiving weekend like a true pirate:\n",
              "\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Host a swashbucklin' feast with yer mateys, complete with a bounty of turkey, grog, and plenty o\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Temperature\n",
        "\n",
        "In the OpenAI API, temperature is a parameter that controls the randomness of the generated text. A higher temperature value (e.g., 0.8) makes the output more diverse and creative by allowing the model to explore different word choices, while a lower value (e.g., 0.2) makes the output more deterministic and focused by favoring the most likely words."
      ],
      "metadata": {
        "id": "3cSyMKOJ32s2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Tell me about large language models\"\n",
        "\n",
        "temperatures = [0.2, 0.7, 2.0]\n",
        "for temperature in temperatures:\n",
        "  response = generate_response(prompt, temperature=temperature)\n",
        "  # response = generate_response_langchain(prompt, temperature=temperature)\n",
        "  print(\"Response for prompt [i]%s[/i] at temperature = %f is \\n %s\\n\"%(prompt, temperature, response))\n",
        "  print(\"--------------------\")"
      ],
      "metadata": {
        "id": "M08hJXlO3Orw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "c048d244-764b-4d97-8861-a38d1088599d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Response for prompt \u001b[3mTell me about large language models\u001b[0m at temperature = \u001b[1;36m0.200000\u001b[0m is \n",
              " Large language models are a type of artificial intelligence \u001b[1m(\u001b[0mAI\u001b[1m)\u001b[0m model that is trained to understand and generate \n",
              "human language. These models are designed to process and generate natural language text, and they have the ability \n",
              "to understand and respond to human language in a way\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Response for prompt <span style=\"font-style: italic\">Tell me about large language models</span> at temperature = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.200000</span> is \n",
              " Large language models are a type of artificial intelligence <span style=\"font-weight: bold\">(</span>AI<span style=\"font-weight: bold\">)</span> model that is trained to understand and generate \n",
              "human language. These models are designed to process and generate natural language text, and they have the ability \n",
              "to understand and respond to human language in a way\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Response for prompt \u001b[3mTell me about large language models\u001b[0m at temperature = \u001b[1;36m0.700000\u001b[0m is \n",
              " Large language models are a type of artificial intelligence that can understand and generate human language. They \n",
              "are trained on vast amounts of text data from the internet and other sources, allowing them to learn the patterns \n",
              "and nuances of language.\n",
              "\n",
              "These models are based on a\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Response for prompt <span style=\"font-style: italic\">Tell me about large language models</span> at temperature = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.700000</span> is \n",
              " Large language models are a type of artificial intelligence that can understand and generate human language. They \n",
              "are trained on vast amounts of text data from the internet and other sources, allowing them to learn the patterns \n",
              "and nuances of language.\n",
              "\n",
              "These models are based on a\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Response for prompt \u001b[3mTell me about large language models\u001b[0m at temperature = \u001b[1;36m2.000000\u001b[0m is \n",
              " Large language models are transformative AI algorithms trained to understand and generate natural language text by\n",
              "incorporating statistical properties of language from a massive amount of training data. By leveraging deep \n",
              "learning techniques, these models aim to predict the next word in a sentence given some idea originating\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Response for prompt <span style=\"font-style: italic\">Tell me about large language models</span> at temperature = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.000000</span> is \n",
              " Large language models are transformative AI algorithms trained to understand and generate natural language text by\n",
              "incorporating statistical properties of language from a massive amount of training data. By leveraging deep \n",
              "learning techniques, these models aim to predict the next word in a sentence given some idea originating\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Max tokens\n",
        "\n",
        "In the OpenAI API, max tokens is a parameter that specifies the maximum length or token count for the generated text. It allows you to limit the length of the response to a specific number of tokens, ensuring that the output does not exceed the desired length constraint."
      ],
      "metadata": {
        "id": "3coEs21E5zwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Tell me about large language models\"\n",
        "\n",
        "max_tokens_list = [10, 20, 100]\n",
        "for max_tokens in max_tokens_list:\n",
        "  response = generate_response(prompt, max_tokens=max_tokens)\n",
        "  # response = generate_response_langchain(prompt, max_tokens=max_tokens)\n",
        "  print(\"Response for prompt [i]%s[/i] at max_tokens = %d: \\n %s \\n\"%(prompt, max_tokens, response))\n",
        "  print(\"-------------------\")"
      ],
      "metadata": {
        "id": "Y2dJQmCL4dfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "1dd7135d-2c3a-4307-a53c-46e35d2ab1f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Response for prompt \u001b[3mTell me about large language models\u001b[0m at max_tokens = \u001b[1;36m10\u001b[0m: \n",
              " Large language models are a type of artificial intelligence \u001b[1m(\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Response for prompt <span style=\"font-style: italic\">Tell me about large language models</span> at max_tokens = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>: \n",
              " Large language models are a type of artificial intelligence <span style=\"font-weight: bold\">(</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "-------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">-------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Response for prompt \u001b[3mTell me about large language models\u001b[0m at max_tokens = \u001b[1;36m20\u001b[0m: \n",
              " Large language models are a type of artificial intelligence \u001b[1m(\u001b[0mAI\u001b[1m)\u001b[0m model that is designed to understand and generate\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Response for prompt <span style=\"font-style: italic\">Tell me about large language models</span> at max_tokens = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>: \n",
              " Large language models are a type of artificial intelligence <span style=\"font-weight: bold\">(</span>AI<span style=\"font-weight: bold\">)</span> model that is designed to understand and generate\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "-------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">-------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Response for prompt \u001b[3mTell me about large language models\u001b[0m at max_tokens = \u001b[1;36m100\u001b[0m: \n",
              " Large language models are a type of artificial intelligence \u001b[1m(\u001b[0mAI\u001b[1m)\u001b[0m model that is designed to understand and generate\n",
              "human language. These models are trained on vast amounts of text data and are capable of performing a wide range of\n",
              "natural language processing tasks, such as language translation, text summarization, question answering, and more.\n",
              "\n",
              "One of the key characteristics of large language models is their ability to generate human-like text based on the \n",
              "input they receive. This makes them particularly useful for tasks such as generating realistic-sounding dialogue \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Response for prompt <span style=\"font-style: italic\">Tell me about large language models</span> at max_tokens = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>: \n",
              " Large language models are a type of artificial intelligence <span style=\"font-weight: bold\">(</span>AI<span style=\"font-weight: bold\">)</span> model that is designed to understand and generate\n",
              "human language. These models are trained on vast amounts of text data and are capable of performing a wide range of\n",
              "natural language processing tasks, such as language translation, text summarization, question answering, and more.\n",
              "\n",
              "One of the key characteristics of large language models is their ability to generate human-like text based on the \n",
              "input they receive. This makes them particularly useful for tasks such as generating realistic-sounding dialogue \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "-------------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">-------------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Template\n",
        "\n",
        "A prompt template is a predefined structure or format for generating requests to an AI model. It typically includes specific placeholders or variables that can be filled with user-specific content, allowing for the easy generation of tailored queries or instructions while maintaining a consistent format."
      ],
      "metadata": {
        "id": "S6sQM_eK77XE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single variable"
      ],
      "metadata": {
        "id": "qsiQ2Ens8wbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"Tell me about {topic}\"\"\"\n",
        "\n",
        "prompt = prompt_template.format(topic=\"GPT\")\n",
        "response = generate_response(prompt, max_tokens=100)\n",
        "# response = generate_response_langchain(prompt, max_tokens=100)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "X5HyXcRE6Gk6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "bd93854a-60ab-4045-a649-39a77d79d5c1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "GPT, or Generative Pre-trained Transformer, is a type of language model developed by OpenAI. It is designed to \n",
              "generate human-like text by predicting the next word in a sentence based on the context of the preceding words. GPT\n",
              "uses a transformer architecture, which allows it to process and generate text by considering the relationships \n",
              "between words in a sentence.\n",
              "\n",
              "GPT models are pre-trained on a large corpus of text data, which enables them to learn the nuances of language and \n",
              "generate coherent and contextually\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">GPT, or Generative Pre-trained Transformer, is a type of language model developed by OpenAI. It is designed to \n",
              "generate human-like text by predicting the next word in a sentence based on the context of the preceding words. GPT\n",
              "uses a transformer architecture, which allows it to process and generate text by considering the relationships \n",
              "between words in a sentence.\n",
              "\n",
              "GPT models are pre-trained on a large corpus of text data, which enables them to learn the nuances of language and \n",
              "generate coherent and contextually\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Two variables"
      ],
      "metadata": {
        "id": "OgOvMp2781YF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"Tell me about {topic} in {language}\"\"\"\n",
        "\n",
        "prompt = prompt_template.format(topic=\"GPT\", language=\"French\")\n",
        "response = generate_response(prompt, max_tokens=100)\n",
        "# response = generate_response_langchain(prompt, max_tokens=100)\n",
        "\n",
        "print(response)\n",
        "\n",
        "print(\"-------------\")\n",
        "\n",
        "prompt = prompt_template.format(topic=\"ChatGPT\", language=\"Spanish\")\n",
        "response = generate_response(prompt, max_tokens=100)\n",
        "# response = generate_response_langchain(prompt, max_tokens=100)\n",
        "\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "LrT6aoD08TSr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "7f708d8c-e193-457e-9b49-e426bd3138e2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "GPT, ou \u001b[32m\"Generative Pre-trained Transformer\"\u001b[0m, est un modèle de langage basé sur l'intelligence artificielle qui a \n",
              "été développé par OpenAI. Il s'agit d'un système de traitement du langage naturel qui utilise un réseau de neurones\n",
              "pour générer du texte de manière autonome. GPT est capable de comprendre et de produire du langage humain de \n",
              "manière fluide, ce qui le rend utile dans de nombreuses applications\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">GPT, ou <span style=\"color: #008000; text-decoration-color: #008000\">\"Generative Pre-trained Transformer\"</span>, est un modèle de langage basé sur l'intelligence artificielle qui a \n",
              "été développé par OpenAI. Il s'agit d'un système de traitement du langage naturel qui utilise un réseau de neurones\n",
              "pour générer du texte de manière autonome. GPT est capable de comprendre et de produire du langage humain de \n",
              "manière fluide, ce qui le rend utile dans de nombreuses applications\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "-------------\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">-------------\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ChatGPT es un modelo de lenguaje desarrollado por OpenAI que utiliza inteligencia artificial para generar \n",
              "respuestas y mantener conversaciones en lenguaje natural. Utiliza una red neuronal de gran escala para comprender y\n",
              "generar texto de manera coherente y relevante. ChatGPT ha sido entrenado en una amplia variedad de temas y puede \n",
              "mantener conversaciones sobre una amplia gama de temas, desde noticias y cultura hasta ciencia y tecnología. Es cap\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ChatGPT es un modelo de lenguaje desarrollado por OpenAI que utiliza inteligencia artificial para generar \n",
              "respuestas y mantener conversaciones en lenguaje natural. Utiliza una red neuronal de gran escala para comprender y\n",
              "generar texto de manera coherente y relevante. ChatGPT ha sido entrenado en una amplia variedad de temas y puede \n",
              "mantener conversaciones sobre una amplia gama de temas, desde noticias y cultura hasta ciencia y tecnología. Es cap\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### More variables\n"
      ],
      "metadata": {
        "id": "myXKG42R9NTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"Tell me about {topic} in {language}. \\\n",
        "Use atmost {sentences} sentences\"\"\"\n",
        "\n",
        "prompt = prompt_template.format(topic=\"GPT\", language=\"English\", sentences=2)\n",
        "response = generate_response(prompt, max_tokens=100)\n",
        "# response = generate_response_langchain(prompt, max_tokens=100)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "7ys_u8Q59AE5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "a5679941-0637-4e20-94c7-0ebe1d6f82cd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "GPT, or Generative Pre-trained Transformer, is a state-of-the-art language model developed by OpenAI that uses deep\n",
              "learning to generate human-like text. It has been trained on a diverse range of internet text and is capable of \n",
              "understanding and generating natural language in a wide variety of contexts.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">GPT, or Generative Pre-trained Transformer, is a state-of-the-art language model developed by OpenAI that uses deep\n",
              "learning to generate human-like text. It has been trained on a diverse range of internet text and is capable of \n",
              "understanding and generating natural language in a wide variety of contexts.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}